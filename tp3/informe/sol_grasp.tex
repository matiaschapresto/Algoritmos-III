 \section{Metaheuristica GRASP: Solucion propuesta}

Dado que la metaheur\'istica GRASP es una combinaci\'on entre una heur\'istica golosa aleatorizada y una b\'usqueda local, decidimos utilizar nuestras heur\'isticas previamente mencionadas, con algunas modificaciones.

\subsection{Modificaci\'on a la heur\'istica golosa}

\vspace{2mm}

Durante el ciclo del algoritmo goloso, recordemos que la primera instrucci\'on del ciclo principal, al igual que el algoritmo de Dijkstra, es obtener el m\'inimo nodo de la cola segu\'un $w_2$. En lugar de esto, ahora armamos una lista restringida de canditatos, o RCL. El algoritmo ahora tiene dos par\'ametros, $tipo\_ejecucion$ que indica tres tipos de ejecuci\'on: determin\'istico, por valor y por cantidad, y un par\'ametro $\beta$. El tipo determin\'istico es an\'alogo a la heur\'istica golosa antes descripta, simplemente tomando el m\'inimo y el par\'ametro $\beta$ es ignorado.

\vspace{2mm}

El tipo de ejecuci\'on por valor arma una lista de candidatos filtrados por su valor, seg\'un un porcentaje de alejamiento del valor del m\'inimo, indicado por el par\'ametro $\beta$. Es decir, se toma la cola y se filtran los candidatos factibles cuyo valor sobrepase $(\beta + 1)*valor\_del\_minimo$). Luego se elige al azar uno de los candidatos. 
\vspace{2mm}

El tipo de ejecuci\'on por cantidad se basa en tomar la cola, y tomar los $\beta$ nodos de valor m\'inimo. Luego se elige uno al azar. Como la cola est\'a ordenada, cumple la condici\'on de RCL por cantidad, con lo que basta tomar un n\'umero aleatorio $i$ entre $0$ y  $min\{cola.size(), parametro\_beta\} -1$ y devolver el $i$-\'esimo elemento de la cola.\\
\textbf{Nota: } Los numeros aleatorios generados para elegir de la RCL en un principio se realizaban con los generadores uniformes de c++11, pero dado que en las mediciones se disparaban los tiempos de ejecucion al usar la libreria random, utilizamos el \texttt{rand()} legacy de C con una semilla inicial \texttt{time(NULL)}.
\vspace{2mm}

Por otro lado, el invariante de Dijkstra nos asegura que tomando el m√≠nimo en cada iteraci\'on, podemos sacarlo de la cola y estar seguros de que no volver\'a a ser actualizado (por principio de optimalidad de Bellman aplicado a caminos m\'inimos). El hecho tomar uno aleatorio no nos asegura esto, por lo tanto cada nodo puede ser visitado y encolado m\'as de una vez. En particular cada nodo es encolado tantas veces como pueda ser mejorado por todos sus vecinos, y sin tener alguna tabla de nodos visitados, el algoritmo itera hasta no poder mejorar m\'as ning\'un nodo, momento en el que se vaci\'a la cola y de esa forma llega a la soluci\'on golosa determin\'istica. Notamos esto prematuramente en la experimentaci\'on al obtener resultados id\'enticos entre la heur\'stica golosa normal y aleatorizada en absolutamente todos los casos y decidimos solucionarlo marcando cada vez que un nodo ingresa en la cola de prioridad y restringirlo a una sola vez, mediante un $vector<bool>$. De esta forma nos aseguramos de esto, y una vez implementada esta mejora, comenzamos a obtener soluciones distintas entre ambos algoritmos, y pudimos ver distintos resultados al variar el par\'ametro $\beta$ (mientras m\'as pequeno, m\'as se acerca al resultado determin\'istico).

\vspace{2mm}

\begin{algorithmic}

\While{ $ !cola=\emptyset$ }
	\If{$tipo\_ejecucion == deterministico$}
    	 \State $nodo \: minimo = minimo(cola)$    
    \ElsIf{$tipo\_ejecucion == por\_cantidad$}
		\State $int \: random = random(0, min\{cola.size(), parametro\_beta\} -1)$
		\State $ \: minimo = cola[random]$
		\Comment $O(random)$, no es iterador de acceso aleatorio
	\ElsIf{$tipo_ejecucion == por\_valor$}
		\State $lista \: nodo \: candidatos = \emptyset$
		\State $int \: i = 0$
		\While{$i<tamano(cola)$}
			\If{$ cola[i] \leq valor\_limite $}
				\State $ agregar(cola[i], candidatos) $
			\EndIf
		\EndWhile
		\State $int \: random = random(0, min\{cola.size(), parametro\_beta\} -1)$
		\State $ \: minimo = candidatos[random]$
		\State $visitados[minimo] = true$
		\EndIf
		
\EndWhile
\end{algorithmic}

\vspace{2mm}

No fue necesario realizar modificaciones a la heur\'istica de b\'usqueda local.

\subsection{Critero de terminaci\'on}

Fijada ya la heur\'istica golosa aleatorizada, y la heur\'istica de b\'usqueda local, queda definir por el criterio de terminaci\'on.

\vspace{2mm}

Hay dos criterios implementados:

\begin{enumerate}
\item Cantidad de iteraciones l\'imite (fijo o variable)
\item Cantidad de iteraciones sin mejora consecutivas
\end{enumerate}

Cantidad de iteraciones l\'imite, como su nombre lo indica itera hasta un l\'imite dado, ya sea una constante, o una variable del problema, por ejemplo la cantidad de nodos del grafo. Cantidad iteraciones sin mejora corta la iteraci\'on cuando se haya alcanzado una cantidad de iteraciones m\'inimas sin que haya habido alguna mejora en el camino.

\vspace{2mm}

\subsection{Consideraciones}

Dada la naturaleza aleatoria de la heur\'istica greedy aleatorizada, en una cantidad de casos despreciable en cuanto al total de experimentos (pero aun as\'i, ocurrieron), la heur\'istica, a\'un habiendo un camino factible en el grafo, no pudo proporcionar una soluci\'on. Por esto, decidimos validar la soluci\'on obtenida del algoritmo goloso, y en caso de que no sea v\'alida, ejecutarlo nuevamente hasta llegar a un tope de iteraciones fijo. Superado este tope de iteraciones, ajustamos el par\'ametro $\beta$ de GRASP, en el caso de que la b\'usqueda golosa sea por cantidad, lo decrementamos en $1$, en el caso por valor, simplemente lo fijamos en $0$ lo cual equivale a la b\'uqueda golosa determin\'istica.

\subsection{Pseudoc\'odigo}

Nota: la entrada $criterios$ se refiere a las variables:

\begin{enumerate}
\item $tipo\_golosa$ : el tipo de ejecuci\'on para la parte golosa.
\item $tipo\_bq$ : el tipo de ejecuci\'on para la b\'usqueda local
\item $\beta$ : el par\'ametro para armar la RCL de la parte golosa.
\item $citerio\_terminacion$ : el criterio de terminaci\'on de GRASP.
\item $max\_its$ : la cantidad de iteraciones l\'mite del primer criterio de terminaci\'on.
\item $max\_its\_sin\ _mejora$ : la cantidad de iteraciones en la cual el segundo criterio debe cortar el algoritmo sin obtener mejora.
\item $bad\_rgreedy\_its$ : la cantidad de iteraciones consecutivas para las cuales corremos la heur\'istica golosa aleatorizada hasta que de una soluci\'on factible.
\end{enumerate}

\begin{algorithmic}[1]

\Procedure{$Sol\_GRASP$}{$Grafo\: g, \:vertice\: v_1,\: vertice \: v_2, \: int \: k, criterios$}{$\rightarrow lista<eje>\: camino$}

	\Statex
	\State $bool \: condicion\_terminacion\: =\: false$
    \State $lista<eje> \:mejor\_solucion\: = \emptyset$
    \State $int \:costo\_mejor\_solucion\: =\: \inf$
    \State $lista<eje> \:camino\: = \emptyset$
    \State $int\: cant\_iters \:= \:0$
    \State $int\: cant\_iters\_sin\_mejora \:= 0$
    \State $int\: cant\_iters\_sin\_sol\_rgreedy\_factible = 0$
    \State $ bool\: sol\_valida\_rgreedy\: =\: false $
    \State $vector<pair<int, costo> > \: mejora\_iters\_grasp$
    \Statex 

    \While{$!condicion\_terminacion$}

    	\State $camino\: =\: solucion\_golosa(g, v_1,v_2, tipo\_golosa, \beta)$
    	\State $ sol\_valida\_rgreedy= validar\_solucion(camino)$
    	\Comment{Obtenemos solucion greedy}

    	\Statex
    	\If{$hay solucion$}
    		\If{$sol\_valida\_rgreedy$}
    		\Comment{Validamos si es factible}
	
	    			\State $cant\_iters\_sin\_sol\_rgreedy\_factible = 0$
	
	    			\State $int\: mejora\_iteracion\_actual\: = 0$
	        	    \State $int\: cant\_iters\_bqlocal\: = 0$
	
	        	    \Statex
	
	    			\While{$mejora\_iteracion\_actual > 0$}
	    					\Comment{Aplicamos Busqueda Local}
	    					\State $mejora\_iteracion\_actual=busqueda\_local(g, tipo\_bq, camino)$
	    					\State $cant\_iters\_bqlocal++$
	
	    			\EndWhile
	
	    			\State $ int \:  costo\_sol\_actual \: = \: costo\_w_2(camino)$
	
	    			\Statex
	
					\If{$costo\_sol\_actual < costo\_mejor\_solucion$}
					\Comment{Reemplazamos si es mejor solucion}
	
						\If{$cant\_iters>0$}
							\State $ agregar(mejora\_iters\_grasp, par<cant\_iters, costo\_mejor\_solucion - costo\_solucion\_actual>) $
						\EndIf
	        	    	\State $costo\_mejor\_solucion = costo\_sol\_actual$
	        	    	\State $mejor\_solucion = camino$
	        	    
	        	   	    \State $cant\_iters\_sin\_mejora = 0$
	        		\Else
	        			\If{$cant\_iters>0$}
	        				\State $ agregar(mejora\_iters\_grasp, par<cant\_iters, 0)>) $
	        	        \EndIf
	        	        \State $cant\_iters\_sin\_mejora++$
	        	    
	        	    	
	        	\EndIf
	
	        	\State $cant\_iters++$
	    	
	    	    	\Else
	    	    	\Comment{$sol\_valida\_rgreedy = false$}
	    	    	\State $cant\_iters\_sin\_sol\_greedy\_rand\_factible++$
	    	    	\If{$cant\_iters\_sin\_sol\_greedy\_rand\_factible\geq bad\_rgreedy\_its$}
	    	    		\If{$tipo\_golosa == por\_cantidad$}
	    	    		\Comment Maximo de its de greedy sin Solucion
	    	    	            \If{$parametro\_beta\geq2$}
	    	    	            	\Comment Ajustamos parametros de GRASP
	    	    	                \State $parametro\_beta--$
	    	    	            \EndIf
	    	    	    \ElsIf{$tipo\_golosa == por\_valor$}
	
	        	    	\State $parametro_beta = 0$
	        		\EndIf
	        		\State $cant\_iters\_sin\_sol\_greedy\_rand\_factible = 0$
	        	\EndIf
        	\EndIf
        \Else
        \Comment No hay Solucion
        	\State $break$
        \EndIf	
    \If{$criterio\_terminacion == 1$}
    \Comment{Si se cumple el criterio de terminacion}
           \State $condicion\_terminacion = (cant\_iters < max\_its)$            
        \ElsIf{$criterio\_terminacion == 2$}
            \State $condicion_terminacion = (cant\_iters\_sin\_mejora < max\_its\_sin\ _mejora)$
        \EndIf

       \EndWhile

       \State $return\:  mejor\_solucion$

\EndProcedure
\end{algorithmic}


\subsection{An\'alisis de complejidad}

A continuaci\'on realizaremos el an\'alisis de complejidad te\'orica de una iteraci\'on de la metaheur\'istica GRASP.
\vspace{2mm}


 Dentro del ciclo principal, la primera instrucci\'on es generar una soluci\'on golosa aleatorizada inicial. La complejidad de la heur\'istica golosa determin\'istica es de $O(n^2 + m log n)$. La heur\'istica golosa aleatorizada difiere de la determin\'istica en la elecci\'on del nodo a desencolar, en caso de ser RCL por cantidad, extraer un elemento random de la cola cuesta $(avanzar\: el\: iterador\: de\: la \:cola \:min\{\beta, n\}\:veces)+O(1) eliminar$, en caso de ser por valor, se filtra toda la cola, por lo que cuesta $O(n)$. El hecho de marcar los nodos y encolarlos una sola vez nos indica que el ciclo $while$ externo itera $n$ veces.

\vspace{2mm}
   
   El ciclo $for$ interno no recibi\'o modificaciones excepto por un condicional que se ejecuta en tiempo constante. El peor de los casos se da cuando la cota $K$ es de mayor peso a cualquier camino simple del grafo y este condicional es siempre verdadero, por lo que el ciclo se vuelve an\'alogo al de Dijkstra y ejecuta en $O(mlogn)$ (sabemos que cada arista se analiza una vez porque marcamos los nodos).

\vspace{2mm}

Por lo tanto en caso de ser RCL por valor la complejidad es de: $O(n^2 + m * logn + \beta * n )$ y en caso de ser por valor es de $O(n^2 + m log n)$. El par\'ametro $\beta$ puede ser acotado por $n$, dado que nunca va a poder armarse una RCL con m\'as de $n$ candidatos, ya que cada nodo est\'a en la cola a lo sumo una vez, con lo cual la complejidad de la heur\'istica aleatorizada no difere de la determin\'istica.


\vspace{2mm}

Acto seguido se valida si esta soluci\'on es factible, en tiempo constante, se declaran enteros y se procede a ejecutar la b\'usqueda local, cuya complejidad es de $O(k*n^2)$, siendo $k$ la cantidad de iteraciones hasta cumplida la condici\'on de terminaci\'on. Lo que resta son simplemente condicionales y asignaciones de tiempo constante, lo que nos da un resultado de $O(n^2 + m log n + k*(n^2)$.

\subsection{Experimentacion: Mediciones de Performance}

A continuacion presentamos los resultados de los experimentos, an\'alogos a los de los algoritmos anteriores, con la salvedad de que para las mismas instancias de grafos, analizaramos primero con RCL por cantidad, con $\beta=n$(peor caso), y luego con RCL por valor, con $\beta=$

\subsubsection{Rendimiento para grafos con densidad cuadratica de aristas}
\begin{itemize}
	\item cant nodos min = $200$
	\item cant nodos max = $350$
	\item peso maximo w1 = $250$
	\item peso maximo w2 = $400$
	\item step nodos = $25$
	\item step aristas = $2500$
	\item aristas minimas = $\frac{n*(n-1)}{8}$
	\item aristas maximas = $\frac{n*(n-1)}{3}$
\end{itemize}								

\begin{center}
	\textbf{Tiempo de ejecuci\'on en microsegundos para esta familia}\\
	\textbf{$y = f(x)$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_variation}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^2$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n_square}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^3$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n_cube}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^4$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n_fourth}.png}
\end{center}


\subsubsection{Rendimiento para grafos con densidad lineal de aristas}
\begin{itemize}
	\item cant nodos min = $200$
	\item cant nodos max = $2000$
	\item peso maximo w1 = $200$
	\item peso maximo w2 = $200$
	\item step nodos = $200$
	\item step aristas = $2500$
	\item aristas minimas = $n-1$
	\item aristas maximas = $10*n$
\end{itemize}								
\begin{center}
	\textbf{Tiempo de ejecuci\'on en microsegundos para esta familia}\\
	\textbf{$y = f(x)$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_variation}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^2$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n_square}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^3$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n_cube}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^4$}\\
	\includegraphics[scale=0.7]{experimentos/resultados_tiempo_grasp_cliques/{grasp.tmpplot_complexity_med_over_n_fourth}.png}
\end{center}

\subsection{Experimentaci\'on de optimalidad}

A continuaci\'on los experimentos de an\'alisis de soluci\'on de la metaheur\'istica, comparadon con el algoritmo exacto y las dem\'as. Para estos experimentos adem\'as, fijando un costo $w_1$ m\'aximo a las aristas, variamos la cota $K$ de los grafos para verificar optimalidad-
\subsubsection{Optimalidad para grafos lineales con $w1 = 120$}
\begin{itemize}
	\item cant nodos min = $200$
	\item cant nodos max = $2000$
	\item peso maximo w1 = $250$
	\item peso maximo w2 = $400$
	\item limit w1 = $12$
	\item step nodos = $100$
	\item step aristas = $2500$
	\item aristas minimas = $2*n$
	\item aristas maximas = $20*n$
\end{itemize}			

\begin{center}
	\includegraphics[scale=0.7]{experimentos/optimalidad_lineal_grasp_120/{comparacion_optimalidad}.png}
\end{center}


3 familias de grafos(baja, alto, intermedio), variando el beta y el tipo de RCL
concluir que el mejor beta es techo(n/128) porque todos los experimentos generales estan asi y porque da la posta!

%--------------------------------------------------------------------------------------------------------------------------------
%te dejo un poco de data aca
%esto es en cliques:
%(carpeta: informe/experimentos/performance-optimalidad-cliques_beta_n_over_128/)
%el resto piolon, igual hace otros experimentos(tienen que ser distintos experimentos el 3d y el pto 4), pero conclui que el posta es n/128 
%
%Golosa:
%	Porcentaje de aciertos(cantidad de veces que GOLOSA da la sol exacta/cantidad de tests hechos): 83.018
%	Porcentaje de alejamiento de la heuristica a la solucion exacta promedio entre golosa y exacta: 4.990
%	Desviacion estandar del alejamiento de la heuristica a la solucion exacta promedio entre golosa y exacta: 18.1754
%GRASP:
%	Porcentaje de aciertos(cantidad de veces que GRASP da la sol exacta/cantidad de tests hechos): 83.018
%	Porcentaje de alejamiento de la heuristica a la solucion exacta promedio entre grasp y exacta: 3.611
%	Desviacion estandar del alejamiento de la heuristica a la solucion exacta promedio entre grasp y exacta: 12.1007
%
%Da lo mismo que golosa en efectividad pero fijate que aca GRASP da mas cercano y con menor dispersion al optimo. :D :D :D
%
%--------------------------------------------------------------------------------------------------------------------------------
