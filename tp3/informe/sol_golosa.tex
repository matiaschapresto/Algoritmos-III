\section{Heur\'istica Golosa}
\subsection{Explicacion detallada de la heur\'istica propuesta}

La heur\'istica desarrollada consiste en una modificaci\'on del algoritmo de camino m\'inimo de Dijkstra.

\subsubsection{Inicializaci\'on}

En la etapa de inicializaci\'on se declaran cuatro vectores a utilizar:

\begin{enumerate}

\item CostosW2
\item Predecesores
\item CostoRecorrido
\item CostosW1
\end{enumerate}

CostosW2, es an\'alogo al vector distancias del algoritmo de Dijkstra, siendo $w_2$ la distancia a minimizar, guarda el costo $w_2$ del camino provisorio para cada nodo que va armando el algoritmo. Predecesores es an\'alogo al vector predecesores de dicho algoritmo, indicando para cada nodo cu\'al es su predecesor en su camino, mientras que CostoRecorrido almacena el costo $w_1$ del camino recorrido.

\vspace{2mm}

CostosW1 almacena el costo $w_1$ del camino m\'inimo de cada nodo hasta el nodo de llegada, por razones que explicamos a continuaci\'on:

\vspace{2mm}

Luego de la declaraci\'on de los vectores, se calculan los caminos m\'inimos en cuanto a costo $w_1$ de todos los nodos hacia el nodo de llegada. Ya que el grafo es simple, las aristas no tienen orientaci\'on definida, por lo cual dados dos nodos $v_1$ y $v_2$, el camino m\'inimo de $v_1$ a $v_2$ es igual al camino m\'inimo de $v_2$ a $v_1$. Esto nos permite ejecutar una \'unica vez el algoritmo de Dikjstra desde el nodo de llegada hasta todos los dem\'as sobre $w_1$ y obtener lo buscado.

\vspace{2mm}

Una vez obtenidos los caminos m\'inimos de cada nodo a la llegada en cuanto a costo $w_1$, \'estos nos permiten conocer lo siguiente:

\begin{enumerate}
\item Al iniciar el algoritmo, aquellos nodos para las cuales no existe un camino de longitud $w_1 \leq K$ hasta el nodo llegada, los cuales nuestro algoritmo va a ignorar.
\item En medio de la ejecuci\'on del algoritmo, desde un nodo $v$ podemos saber si el nodo $x$ de la pro\'oxima arista $(v,x$ a considerar tiene al menos un camino $c$ hasta el nodo llegada tal que, el costo del camino formado por la uni\'on de $c$ ($costoW1(x)$) y el recorrido hasta ahora ($costoRecorrido(v)$) es $\leq K$. En caso de no tenerlo, desde ese nodo no hay un camino v\'alido hasta la llegada, por lo tanto nuestro algoritmo va a descartar esta arista por otra que tenga al menos un camino posible hasta la llegada. Esto lo podemos conocer, ya que la ejecuci\'on de Dijkstra inicial nos brinda el costo $w_1$ del camino m\'inimo desde el nodo $x$ hasta la llegada, por lo tanto  si $costoRecorrido(v)$ + $costo(v,x)$ + $Costosw_1(x)$ $\leq$ $K$ sabemos que existe al menos este camino v\'alido, caso contrario descartamos la arista.
\end{enumerate}

\begin{center}
\includegraphics[scale=0.58]{img/inicializacion.png}
\end{center}	
\vspace{2mm}

Este dibujo representa la ejecuci\'on de la inicializaci\'on de la heur\'stica, donde el algoritmo de Dijkstra calcula los costos $w_1$ de los caminos m\'inimos de todos los nodos al nodo llegada (en violeta), y puede verse que aquellos nodos con caminos de costo mayor a $K$ ser\'an descartados.

\subsubsection{Heur\'istica golosa}

El algoritmo goloso en s\'i comparte su estructura con el algoritmo de Dijkstra sobre los costos $w_2$. El agregado al algoritmo es la estrategia previamente explicada, teniendo la informaci\'on que nos brindan $CostosW1$ y $CostoRecorrido$, cuando sacamos un nodo $v$ de la cola y procedemos a actualizar sus vecinos $x$, s\'olo vamos a considerar actualizar los valores $CostosW2$ y $precedesor$ para aquellos que sean factibles, es decir, aquellos para los cuales el costo $w_1$ del camino recorrido potencial recorrido hasta $v$ + el costo de la arista entre los nodos $(v,x)$ +  el costo $w_1$ del camino m\'inimo de $x$ a la llegada es menor o igual a K, dicho en t\'erminos del algoritmo: $costoRecorrido[v]+costo(v,x)+CostosW1[x]\leq K$. Esto nos asegura que el camino de un nodo nunca va a ser actualizado por un camino no factible.

\vspace{2mm}

La componente golosa del algoritmo, al igual que en el algoritmo de Dijkstra, es la elecci\'on en cada iteraci\'on del m\'inimo nodo de la cola de nodos.

\subsubsection{Pseudoc\'odigo}


\begin{algorithmic}[1]
\Statex

\Procedure{Heur\'istica Golosa}{grafo g, nodo u, nodo v, cota K}{ -$>$ camino}

\State $ vector<int> \: costosw_1[n] $
\State $vector<int> costosw_2[n]$
\State $vector<int> predecesores[n]$
\State $ vector<int> \: costoRecorrido[n] $
\State $camino \: c \gets [] $
\State $colaPrioridad \: cola \gets []$

\Statex

\State $ Dijkstra(g, v, costosw_1) $

\Statex

\For{$i\: from \: 0 \: to \: n-1$}
	\State $ costosw_2[i] \gets \infty $
	\State $ predecesores[i] \gets NULL $
	\State $ costoRecorrido[i] \gets 0 $	
\EndFor

\State $ costosw_2[u] \gets 0 $
\Statex
\State $ cola.push(costosw_2, u) $

\While{$cola != []$}
	\State $ par<costow_2, nodo> actual \gets cola.pop $
	\For{$ w \: : \: adyacentes(actual_2) $}
		\If{ $costoRecorrido[actual_2] + costow_1Arista(actual_2,w) + costosw_1(w)  \leq K $ }
		

			\If{$ costosw_2[w] > costosw_2[actual_2] + costow_2Arista(actual,w) $}
			\State $ costosw_2[w] \gets costosw_2[actual_2] + costow_2Arista(actual,w) $
			\State $ costoRecorrido[w] \gets costoRecorrido[actual_2] + costow_1Arista(actual_2,w) $
			\State $ predecesor[w] = actual $
			\State $cola.push(costow_2(w), w)$


			\EndIf

		\EndIf
	\EndFor

\EndWhile

\State $ c \gets reconstruirCamino(predecesor,v) $
\State $ return \:c $

\EndProcedure
\end{algorithmic}


\subsubsection{Complejidad}

El algoritmo comienza declarando vectores de longitud de tamano $n$, un camino de tamano $n^2$ y una cola de prioridad, en total tiempo $O(n^2)$. Acto seguido ejecuta el algoritmo de Dijkstra desde nodo llegada a todos los dem\'as, en tiempo $O((m+n)log n)$. Se ejecuta un ciclo que deja preparados los vectores a utilizar por el ciclo goloso, en $O(n)$ y dos asignaciones de tiempo constante.

\vspace{2mm}

El ciclo while va a iterar a lo sumo $n$ veces, ya que hay nodos no factibles que no ser\'an anadidos, y aquellos que si lo sos, son anadidos a lo sumo una \'unica vez (por la demostraci\'on de Dijkstra, al elegir el nodo con costo m\'inimo de la cola nos aseguramos que ese va a ser su costo m\'inimo y no va a ser necesario actualizarlo nuevamente). En cada iteraci\'on se obtiene y elimina el m\'inimo elemento de la cola en $O(logn)$. Nos queda analizar el ciclo $for$ interior, que para cada nodo itera sobre su lista de adyacentes. Como cada nodo es agregado una vez, entonces cada arista en la lista de cada nodo es examinada una vez durante el transcurso del algoritmo, por lo cual este ciclo for itera $m$ veces durante el transcurso del algoritmo. Dentro de este ciclo se realizan operaciones de tiempo constante excepto la operaci\'on $push$,la cual ejecuta en tiempo $O(logn)$, con lo cual el ciclo $for$ posee complejidad $O(mlogn)$.

\vspace{2mm}

Esto nos deja con una complejidad de: $O(n^2) + O((m+n)log n) + O(n log n) + O(n log m) = O(n^2 + m log n)$.

\vspace{2mm}

Usamos el tipo $set$ de la librer\'ia STL de c++, la cual nos asegura estas complejidades:
\begin{enumerate}
\item http://www.cplusplus.com/reference/set/set/
\item http://www.cplusplus.com/reference/set/set/begin/
\item http://www.cplusplus.com/reference/set/set/erase/
\end{enumerate}

\subsubsection{Soluci\'on Factible}

A continuaci\'on, vamos a demostrar que en caso de haber alg\'un camino factible desde la salida a la llegada (de costo $w_1$ total $\leq K$), la heur\'istica siempre va a encontrar un camino factible y por lo tanto, devolver una soluci\'on.

\vspace{2mm}

Consideremos el camino $C$, de costo $w_1$ m\'inimo del nodo de salida $u$ al nodo de llegada $v$. Supongamos que este existe y adem\'as su costo total es menor a la cota $K$. Supongamos que el algoritmo no puede encontrar un camino factible, y lleguemos a un absurdo. Tomemos a $x$, como el \'ultimo nodo $\in C$ para el cual el algoritmo puede actualizar sus valores, es decir, el \'ultimo nodo para el cual tuvo algu\'n vecino $a$ tal que $costoRecorrido[a] + costow_1Arista(a,x) + costosw_1(x)  \leq K $ y el algoritmo actualiz\'o valores. 

\vspace{2mm}

Sabemos que este nodo existe ya que existe $C$ un camino factible de costo m\'inimo $w_1$ $\leq K$ de $u$ a $v$, por lo tanto este nodo es al menos el segundo nodo de $C$, ya que sabemos que $costoRecorrido[u] + costow_1Arista(u,segundo) + costosw_1(segundo) \leq K $, al ser $costoRecorrido[u]=0$ y $costow_1Arista(u,segundo) + costosw_1(segundo)\leq K$ necesariamente ya que es un subcamino de $C$, y que el problema de camino m\'ino cumple el principio de optimalidad de Bellman, y el camino m\'inimo de $u$ a $v$ puede ser descompuesto como dos caminos $u-segundo$ y $segundo-v$ que a su vez son m\'inimos.

\vspace{2mm}

\includegraphics[scale=0.6]{img/caminoC.png}

Ahora consideremos el nodo siguiente del camino, llam\'emosle $y$. $y$ es el primer nodo del camino $C$ para el cual el algoritmo no puede actualizarlo ni insertarlo en la cola. Pero sabemos que $x$ es adyacente a $y$, y sabemos que para $x$, por haber sido actualizado por el algoritmo vale $costoRecorrido[x] + costosw_1(x) \leq K$. Y por no haber podido ser actualizado $y$ desde $x$, vale $costoRecorrido[x] + costow_1Arista(x,y) + costosw_1(y)  > K$. Pero esto nos deja en un absurdo, ya que $costosw_1(x)=  costow_1Arista(x,y) + costosw_1(y)$ exactamente, ya que ambos nodos forman parte de $C$, y por principio de optimalidad al sere $C$ el camino m\'inimo,  el camino m\'nimo de $x$ a la llegada va a ser el subcamino de $C$ de $x$ a la llegada, del cual forma parte $y$ y la arista entre $x$ e $y$.	

\vspace{2mm}

Llegamos a un absurdo al suponer que existe el camino $C$, y que el algoritmo en alg\'un punto para un nodo de $C$ no puede actualizarlo formando un camino factible. LLegamos a la conclusi\'on de que, o bien no existe ningu\'un camino factible en el grafo, o existe al menos uno y el algoritmo lo devuelve.

\subsection{Nivel de optimalidad de las soluciones}

\subsection{Experimentacion: Mediciones de Performance}
En esta secci\'on se mostrar\'an resultados de complejidad temporal emp\'irica, veremos que los resultados coinciden razonablemente con el an\'alisis de complejidad te\'orica..
Para tener una mejor idea del comportamiento del algoritmo, realizamos pruebas sobre grafos aleatorios de distintos tama\~nos(en cantidad de nodos), y por cada cantidad $n$ de nodos, variamos las densidades de aristas dentro de cierto rango alrededor de una funcion de $n$, las densidades elegidas fueron:
\begin{itemize}
	\item m = $a*n + b$. Es decir una cantidad lineal de aristas en base a los nodos. $a \in \mathbb{N}_{>1}$
	\item m = $\frac{n*(n-1)}{2}$. Es decir grafos cercanos o iguales a cliques de n nodos.
\end{itemize}


\textbf{Nota: } Como mencionamos anteriormente, las funciones son variadas en un rango, es decir, por ejemplo, para el caso de cliques, los grafos generados tienen entre $\frac{n*(n-1)}{5}$ y $\frac{n*(n-1)}{2}$ aristas para aleatorizar mas la generacion de grafos densos.\\

\textbf{Nota: } Los graficos que contienen puntos rojos y una curva verde, indican, para cada valor del eje X(cantidad de nodos), los puntos rojos son los tiempos de ejecucion para los diferentes valores de aristas en el rango de la familia, asimismo, la curva verde indica el promedio de estos puntos para cada X. \\
\textbf{Nota: }Para verificar que se trata de una curva cuadratica dividimos las funciones por $n^1$, $n^2$, $n^3$, $n^4$ y como en los trabajos practicos anteriores concluimos de que curva se trata.\\

\subsubsection{Consideraciones acerca de la complejidad te\'orica}

En la secci\'on de anal\'isis de complejidad del algoritmo concluimos acotando la complejidad en $O(n^2 + m log n)$. Sin embargo, como informamos en la secci\'on anterior, nos vamos a limitar a dividir las funciones por potencias de $n$ de $1$ a $4$. Esto se debe a, adem\'as de una mayor simplicidad, a que en el caso de prueba con $m = a*n+b$, $m$ es lineal en cuanto a $n$, por lo tanto la complejidad se aproximar\'ia a $n^2 + nlogn$, con lo cual quedar\'a en el orden cuadr\'atico, y consideramos que va a bastar con considerarlo de este orden para realizar el an\'alisis de las divisiones. Por otro lado en el caso $m=n*(n-1)/a$, $m$ es cuadr\'atico en cuanto a $n$, y la complejidad se aproximar\'a a $n^2+n^2log n$, lo cual es del orden $O(n^2log n)$. Pero, considerando que como m\'aximo en nuestra experimentaci\'on usamos $n=2000$, $log(2000) \approx 11$, lo cual es casi despreciable, por lo cual tambi\'en consideraremos al algoritmo en el orden cuadr\'atico para realizar el an\'alisis.



\subsubsection{Rendimiento para grafos con densidad lineal de aristas}
\begin{itemize}
	\item cant nodos min = $50$
	\item cant nodos max = $2000$
	\item peso maximo w1 = $250$
	\item peso maximo w2 = $400$
	\item step nodos = $200 NO ESTOY SEGURO DE ESTO$
	\item step aristas = $2500$
	\item aristas minimas = $n-1$
	\item aristas maximas = $10*n$
\end{itemize}

\begin{center}
	\textbf{Tiempo de ejecuci\'on en microsegundos para esta familia}\\
	\textbf{$y = f(x)$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_lineal/{golosa.tmpplot_complexity_variation}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_lineal/{golosa.tmpplot_complexity_med_over_n}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^2$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_lineal/{golosa.tmpplot_complexity_med_over_n_square}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^3$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_lineal/{golosa.tmpplot_complexity_med_over_n_cube}.png}
\end{center}


\begin{center}
	\textbf{$y = f(x)/x^4$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_lineal/{golosa.tmpplot_complexity_med_over_n_fourth}.png}
\end{center}


\subsubsection{Rendimiento para grafos con densidad cuadratica de aristas}
\begin{itemize}
	\item cant nodos min = $5$
	\item cant nodos max = $500$
	\item peso maximo w1 = $250$
	\item peso maximo w2 = $400$
	\item step nodos = $200$
	\item step aristas = $2500$
	\item aristas minimas = $\frac{n*(n-1)}{9}$
	\item aristas maximas = $\frac{n*(n-1)}{7}$
\end{itemize}								



\begin{center}
	\textbf{Tiempo de ejecuci\'on en microsegundos para esta familia}\\
	\textbf{$y = f(x)$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_clique/{golosa.tmpplot_complexity_variation}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_clique/{golosa.tmpplot_complexity_med_over_n}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^2$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_clique/{golosa.tmpplot_complexity_med_over_n_square}.png}
\end{center}

\begin{center}
	\textbf{$y = f(x)/x^3$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_clique/{golosa.tmpplot_complexity_med_over_n_cube}.png}
\end{center}


\begin{center}	
	\textbf{$y = f(x)/x^4$}\\
	\includegraphics[scale=0.7]{experimentos/golosa/golosa_clique/{golosa.tmpplot_complexity_med_over_n_fourth}.png}
\end{center}

Concluimos en que

\subsection{Experimentaci\'on de optimalidad}
